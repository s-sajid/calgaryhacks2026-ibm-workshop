{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# CalgaryHacks2026 IBM Workshop - Intro\n",
        "\n",
        "Welcome! In this notebook, you will:\n",
        "- connect to an LLM API\n",
        "- send a simple prompt\n",
        "- stream the response live in the notebook\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Before you run\n",
        "\n",
        "1. Install Python (version 3.12.12 used for development)\n",
        "2. Install UV and run `uv sync`\n",
        "3. Generate your Ollama API Key\n",
        "4. Create a `.env` file in this project folder using `cp .env.example .env`\n",
        "5. Add your API key to the `.env` file like this:\n",
        "\n",
        "```env\n",
        "OLLAMA_API_KEY=your_real_api_key_here\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "from dotenv import load_dotenv\n",
        "from ollama import Client\n",
        "from IPython.display import display, Markdown\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/markdown": [
              "API key loaded successfully."
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Load values from .env\n",
        "load_dotenv()\n",
        "\n",
        "api_key = os.getenv(\"OLLAMA_API_KEY\", \"\").strip()\n",
        "\n",
        "if not api_key or api_key == \"your_api_key_here\":\n",
        "    raise ValueError(\n",
        "        \"Missing OLLAMA_API_KEY. Add it to your .env file, then rerun this cell.\"\n",
        "    )\n",
        "\n",
        "display(Markdown(\"API key loaded successfully.\"))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/markdown": [
              "Client created."
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Create API client\n",
        "client = Client(\n",
        "    host=\"https://ollama.com\",\n",
        "    headers={\"Authorization\": f\"Bearer {api_key}\"},\n",
        ")\n",
        "\n",
        "display(Markdown(\"Client created.\"))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/markdown": [
              "Found requested model: `qwen3-next:80b`"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/markdown": [
              "Available models (first n): `cogito-2.1:671b, glm-4.6, glm-4.7, glm-5, kimi-k2:1t, kimi-k2.5, kimi-k2-thinking, qwen3-coder:480b, qwen3-next:80b, qwen3-coder-next`"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Connection + model availability check\n",
        "MODEL_NAME = \"qwen3-next:80b\"\n",
        "\n",
        "try:\n",
        "    model_data = client.list()\n",
        "except Exception as exc:\n",
        "    raise ConnectionError(\n",
        "        \"Could not connect to Ollama API. Check internet access and API key.\"\n",
        "    ) from exc\n",
        "\n",
        "available_models = [m.get(\"model\", \"\") for m in model_data.get(\"models\", [])]\n",
        "\n",
        "if not available_models:\n",
        "    raise RuntimeError(\n",
        "        \"Connected, but no models are available for this account.\"\n",
        "    )\n",
        "\n",
        "if MODEL_NAME in available_models:\n",
        "    selected_model = MODEL_NAME\n",
        "    display(Markdown(f\"Found requested model: `{selected_model}`\"))\n",
        "else:\n",
        "    selected_model = available_models[0]\n",
        "    display(Markdown(\n",
        "        f\"`{MODEL_NAME}` not found. Using `{selected_model}` instead.\"\n",
        "    ))\n",
        "\n",
        "n = 10\n",
        "preview = \", \".join(available_models[:n])\n",
        "display(Markdown(f\"Available models (first n): `{preview}`\"))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "user_prompt = \"Tell me a one-line fun fact about the University of Calgary\"\n",
        "\n",
        "messages = [\n",
        "    {\n",
        "        \"role\": \"user\",\n",
        "        \"content\": user_prompt,\n",
        "    },\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/markdown": [
              "\n",
              "\n",
              "The University of Calgary houses a real 66-million-year-old *Tyrannosaurus rex* fossil named \"Dino\" in its Earth Sciences buildingâ€”making it one of the only universities in the world with a full-sized T. rex on campus! ðŸ¦–"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "resp = client.chat(model=selected_model, messages=messages, stream=False)\n",
        "text = resp.get(\"message\", {}).get(\"content\", \"\")\n",
        "display(Markdown(text))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "aa70e5b5",
      "metadata": {},
      "outputs": [],
      "source": [
        "system_prompt = \"Welcome to CalgaryHacks 2026! Encourage the user for this 24 hour long hackathon and provide them with great ideas.\"\n",
        "\n",
        "user_prompt = \"Can you suggest a great hackathon idea to impress the judges?\"\n",
        "\n",
        "messages = [\n",
        "    {\n",
        "        \"role\": \"system\",\n",
        "        \"content\": system_prompt,\n",
        "    },\n",
        "    {\n",
        "        \"role\": \"user\",\n",
        "        \"content\": user_prompt,\n",
        "    },\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "915c622a",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/markdown": [
              "\n",
              "\n",
              "Absolutely! For **CalgaryHacks 2026**, you need an idea thatâ€™s **local, impactful, technically impressive, and feasible in 24 hours**â€”while standing out from generic \"solve climate change\" projects. Judges love **real-world problems with a unique twist**, especially ones tied to Calgaryâ€™s identity (cowboy culture, energy transition, urban growth, or Western heritage).  \n",
              "\n",
              "Hereâ€™s a **winning idea** that checks all boxes:  \n",
              "\n",
              "---\n",
              "\n",
              "### ðŸŒŸ **\"Barnacle: AI-Powered Food Bank Donation Optimizer\"**  \n",
              "*(A tool for Calgaryâ€™s food banks to sort, track, and distribute donations in real-timeâ€”using computer vision to cut manual labor by 80%)*  \n",
              "\n",
              "#### ðŸŽ¯ **Why This Wins**  \n",
              "- **Hyper-Local Impact**: Calgary has **1 in 8 residents** facing food insecurity (Calgary Food Bank data). Food banks like **Calgary Food Bank** and **Second Harvest** are overwhelmed with manual sortingâ€”wasting hours on categorizing canned goods, fresh produce, and perishables.  \n",
              "- **Unique Twist**: Instead of just \"another donation app,\" we use **on-device AI** to instantly identify items via phone camera (e.g., \"canned tomatoes,\" \"milk carton,\" \"expired yogurt\"), then auto-sort them into categories and flag spoilage risks. No cloud dependency = works offline in low-connectivity areas.  \n",
              "- **Calgary-Specific Flair**: Integrates with **local grocery partnerships** (e.g., Sobeys, Safeway) to predict incoming donations based on surplus dataâ€”so food banks can plan ahead for high-demand items (like fresh produce during summer heatwaves).  \n",
              "- **Technical Wow Factor**:  \n",
              "  - Train a **tiny ML model** (TensorFlow Lite) on common food items using free datasets (e.g., USDA Food Database).  \n",
              "  - Build a **simple Android app** with camera scan â†’ AI classification â†’ dashboard for managers.  \n",
              "  - Add a **\"Donation Pulse\"** feature: Real-time heatmaps showing which neighborhoods need donations most (using anonymized data from shelters).  \n",
              "- **24-Hour Feasibility**:  \n",
              "  - Use pre-trained models (e.g., Teachable Machine for image classification).  \n",
              "  - Build a prototype in 4 hours: Camera UI â†’ basic classification â†’ Firebase dashboard.  \n",
              "  - Polish in 20 hours: Add localization (Calgary-specific food banks), offline mode, and a slick demo video.  \n",
              "\n",
              "#### ðŸ’¡ **Why Judges Will Love It**  \n",
              "- **Social Impact**: Directly helps vulnerable Calgariansâ€”judges prioritize projects with tangible community benefits.  \n",
              "- **Innovation**: Combines edge AI + local data in a way no existing tool does (most \"food waste\" apps focus on restaurants, not food banks).  \n",
              "- **Calgary Pride**: Ties to our cityâ€™s identity (e.g., \"Cowtown\" meets techâ€”like a digital barn for modern food security).  \n",
              "- **Scalable**: Could expand to other cities or even Albertaâ€™s rural communities (where food banks are even more strained).  \n",
              "\n",
              "#### ðŸš€ **Demo Script for Judges**  \n",
              "> *\"Imagine a food bank volunteer spending 3 hours manually sorting a truck of donations. With Barnacle, they scan a can of beans with their phoneâ€”it instantly tags it, checks expiry dates, and routes it to the right shelf. Meanwhile, the dashboard shows: â€˜High demand for protein in Northeast Calgaryâ€”prioritize canned chicken.â€™ In 24 hours, we built this using free AI tools and local data. This isnâ€™t just techâ€”itâ€™s dignity for Calgarians in need.\"*  \n",
              "\n",
              "#### ðŸ”§ **Tech Stack (Simple & Fast)**  \n",
              "- **Frontend**: Android Studio (Kotlin) or Flutter for cross-platform.  \n",
              "- **AI**: TensorFlow Lite (pre-trained model trained on 50+ common food items).  \n",
              "- **Backend**: Firebase (free tier) for real-time database and user auth.  \n",
              "- **Data**: Public datasets (USDA, Calgary Food Bank reports) + Google Maps API for neighborhood heatmaps.  \n",
              "\n",
              "#### ðŸŒŽ **Bonus: Calgary-Specific Hook**  \n",
              "- Partner with **Calgaryâ€™s \"Food Bank Week\"** (June 2026) for a live demo at a local event.  \n",
              "- Add a \"Stampede Edition\" mode: During the Calgary Stampede, track donations of Western-themed items (e.g., \"baked beans,\" \"jerky\") to help event volunteers.  \n",
              "\n",
              "---\n",
              "\n",
              "### ðŸ’¬ **Why This Beats Generic Ideas**  \n",
              "- âŒ *\"Smart city traffic app\"* â†’ Overdone.  \n",
              "- âŒ *\"AI climate change predictor\"* â†’ Too broad, needs 6 months of data.  \n",
              "- âœ… **Barnacle** â†’ Solves a **specific, urgent problem** in Calgary with **provable impact**, using **accessible tech**. Itâ€™s human-centered, local, and demo-ready in 24 hours.  \n",
              "\n",
              "> ðŸ’¡ **Pro Tip**: For extra polish, build a **physical prototype** (e.g., a mock food bank shelf with QR codes for items) to demo live. Judges remember *tangible* demos!  \n",
              "\n",
              "This idea has already won hackathons like **TechFest 2023** (Toronto) and **Hack the North 2024**â€”but with a **Calgary twist**, itâ€™s yours to own. Go crush it! ðŸ¤ ðŸ’»  \n",
              "\n",
              "**Need help refining the tech? Ask me for:  \n",
              "- A step-by-step 24-hour plan  \n",
              "- Free datasets to train your AI model  \n",
              "- How to pitch it in <60 seconds**  \n",
              "Let me know! ðŸ˜Š"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "resp_2 = client.chat(model=selected_model, messages=messages, stream=False)\n",
        "text_2 = resp_2.get(\"message\", {}).get(\"content\", \"\")\n",
        "display(Markdown(text_2))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Try this next\n",
        "- Change the user prompt to your own hackathon theme.\n",
        "- Ask for a 30-second pitch and a simple MVP plan.\n",
        "- Ask for judging criteria and how to optimize for each one.\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "calgaryhacks2026-ibm-workshop",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
