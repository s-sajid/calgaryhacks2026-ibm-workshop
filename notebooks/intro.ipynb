{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# CalgaryHacks2026 IBM Workshop - Intro\n",
        "\n",
        "Welcome! In this notebook, you will:\n",
        "- connect to an LLM API\n",
        "- send a simple prompt\n",
        "- stream the response live in the notebook\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Before you run\n",
        "\n",
        "1. Install Python (version 3.12.12 used for development)\n",
        "2. Install UV and run `uv sync`\n",
        "3. Generate your Ollama API Key\n",
        "4. Create a `.env` file in this project folder using `cp .env.example .env`\n",
        "5. Add your API key to the `.env` file like this:\n",
        "\n",
        "```env\n",
        "OLLAMA_API_KEY=your_real_api_key_here\n",
        "```\n",
        "6. Select the correct kernel (top-right in Jupyter)\n",
        "\n",
        "### Optional: Run Granite locally\n",
        "\n",
        "- Granite models: `https://ollama.com/search?q=granite`\n",
        "- Local Ollama default host/port: `http://localhost:11434`\n",
        "- In the client cell below, uncomment the local connection block and comment out the cloud block.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "from dotenv import load_dotenv\n",
        "from ollama import Client\n",
        "from IPython.display import display, Markdown\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/markdown": [
              "API key loaded successfully."
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Load values from .env\n",
        "load_dotenv()\n",
        "\n",
        "api_key = os.getenv(\"OLLAMA_API_KEY\", \"\").strip()\n",
        "\n",
        "if not api_key or api_key == \"your_api_key_here\":\n",
        "    raise ValueError(\n",
        "        \"Missing OLLAMA_API_KEY. Add it to your .env file, then rerun this cell.\"\n",
        "    )\n",
        "\n",
        "display(Markdown(\"API key loaded successfully.\"))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/markdown": [
              "Client created."
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Create API client using Ollama Cloud (default)\n",
        "client = Client(\n",
        "    host=\"https://ollama.com\",\n",
        "    headers={\"Authorization\": f\"Bearer {api_key}\"},\n",
        ")\n",
        "\n",
        "display(Markdown(\"Client created.\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3b45d8cf",
      "metadata": {},
      "source": [
        "### Optional: Granite 4 local setup (separate path)\n",
        "\n",
        "If you want to run locally instead on your own hardware instead of the cloud:\n",
        "\n",
        "1. Install/start Ollama locally (`http://localhost:11434` is the default host/port).\n",
        "2. Pull a Granite model from: https://ollama.com/search?q=granite: `ollama pull granite4:latest`\n",
        "3. Use the optional local client cell below (uncomment).\n",
        "4. Then either skip the model-check cell, or set `MODEL_NAME = \"granite4:latest\"` in that cell.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "0e020a8c",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Optional local client\n",
        "# Uncomment this block if using a Ollamam locally instead of the cloud API.\n",
        "\n",
        "# client = Client(\n",
        "#     host=\"http://localhost:11434\",\n",
        "# )\n",
        "# local_model = \"granite4:latest\"\n",
        "# display(Markdown(f\"Using local Ollama + {local_model}\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/markdown": [
              "Found requested model: `qwen3-next:80b`"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/markdown": [
              "Available models (first n): `cogito-2.1:671b, glm-4.6, glm-4.7, glm-5, kimi-k2:1t, kimi-k2.5, kimi-k2-thinking, qwen3-coder:480b, qwen3-next:80b, qwen3-coder-next`"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Connection + model availability check\n",
        "MODEL_NAME = \"qwen3-next:80b\"\n",
        "\n",
        "try:\n",
        "    model_data = client.list()\n",
        "except Exception as exc:\n",
        "    raise ConnectionError(\n",
        "        \"Could not connect to Ollama API. Check internet access and API key.\"\n",
        "    ) from exc\n",
        "\n",
        "available_models = [m.get(\"model\", \"\") for m in model_data.get(\"models\", [])]\n",
        "\n",
        "if not available_models:\n",
        "    raise RuntimeError(\n",
        "        \"Connected, but no models are available for this account.\"\n",
        "    )\n",
        "\n",
        "if MODEL_NAME in available_models:\n",
        "    selected_model = MODEL_NAME\n",
        "    display(Markdown(f\"Found requested model: `{selected_model}`\"))\n",
        "else:\n",
        "    selected_model = available_models[0]\n",
        "    display(Markdown(\n",
        "        f\"`{MODEL_NAME}` not found. Using `{selected_model}` instead.\"\n",
        "    ))\n",
        "\n",
        "n = 10\n",
        "preview = \", \".join(available_models[:n])\n",
        "display(Markdown(f\"Available models (first n): `{preview}`\"))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [],
      "source": [
        "user_prompt = \"Tell me a one-line fun fact about the University of Calgary\"\n",
        "\n",
        "messages = [\n",
        "    {\n",
        "        \"role\": \"user\",\n",
        "        \"content\": user_prompt,\n",
        "    },\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/markdown": [
              "\n",
              "\n",
              "The University of Calgary campus sits atop a fossil-rich layer where over 100 dinosaur skeletons have been unearthedâ€”making it one of the most dinosaur-dense university grounds in the world! ðŸ¦–"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "resp = client.chat(model=selected_model, messages=messages, stream=False)\n",
        "text = resp.get(\"message\", {}).get(\"content\", \"\")\n",
        "display(Markdown(text))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "aa70e5b5",
      "metadata": {},
      "outputs": [],
      "source": [
        "system_prompt = \"Welcome to CalgaryHacks 2026! Encourage the user for this 24 hour long hackathon and provide them with great ideas.\"\n",
        "\n",
        "user_prompt = \"Can you suggest a great hackathon idea to impress the judges?\"\n",
        "\n",
        "messages = [\n",
        "    {\n",
        "        \"role\": \"system\",\n",
        "        \"content\": system_prompt,\n",
        "    },\n",
        "    {\n",
        "        \"role\": \"user\",\n",
        "        \"content\": user_prompt,\n",
        "    },\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "915c622a",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/markdown": [
              "\n",
              "\n",
              "Hey there, CalgaryHacks 2026 champ! ðŸ‘‹ First offâ€”**congrats on signing up for this 24-hour whirlwind of creativity and grit!** Whether you're a coding wizard, a design guru, or just someone with big ideas, this is your chance to build something that *matters*. Judges donâ€™t just look for \"cool tech\"â€”they want **real-world impact, local relevance, and a story that sticks with them**. Forget perfection; focus on **one clear problem, one innovative solution, and a demo that makes them say, \"Wow, I wish Iâ€™d thought of that!\"**\n",
              "\n",
              "Hereâ€™s a **proven idea tailored for CalgaryHacks 2026** that checks all the boxes:  \n",
              "ðŸ”¥ **\"EcoPulse: AI-Powered Retrofits for Calgaryâ€™s Aging Buildings\"** ðŸ”¥  \n",
              "\n",
              "### ðŸŒ Why This Stands Out  \n",
              "- **Calgary-Specific Problem**:  \n",
              "  Calgary has over **100,000 buildings built before 2000**â€”many are energy hogs. The cityâ€™s *Net Zero by 2050* plan needs solutions *now*, but retrofitting is expensive and confusing for homeowners. Existing tools are either too technical (for engineers) or too generic (like \"turn off lights\").  \n",
              "- **The Twist**:  \n",
              "  Weâ€™re not just another energy app. **EcoPulse uses AI to turn public data into hyper-local, actionable steps**â€”like \"Your 1970s bungalow in Inglewood could save $300/year by replacing this window *and* adding attic insulation.\" Itâ€™s built for **homeowners, not experts**, with plain English advice.  \n",
              "- **Why Judges Will Love It**:  \n",
              "  - âœ… **Ties to Calgaryâ€™s future**: Directly supports the cityâ€™s climate goals (Calgary Climate Initiative, Albertaâ€™s Net Zero Act).  \n",
              "  - âœ… **Uses real public data**: Leverages the [City of Calgaryâ€™s Open Data Portal](https://data.calgary.ca/) (e.g., building age, energy reports, neighborhood maps).  \n",
              "  - âœ… **Simple but powerful tech**: A web app with a map interface + AI recommendations (using lightweight ML like TensorFlow.jsâ€”no heavy cloud costs!).  \n",
              "  - âœ… **Scalable impact**: Could partner with Calgaryâ€™s \"Green Home Program\" or Alberta Energy to offer rebates.  \n",
              "\n",
              "### ðŸ’¡ How to Build It in 24 Hours (MVP Focus)  \n",
              "| Component | What to Build | Tools to Use (Free & Easy) |  \n",
              "|-----------|---------------|----------------------------|  \n",
              "| **Data Layer** | Pull building age, energy use, and location data from Calgaryâ€™s Open Data Portal | Python (Pandas) + City of Calgary API |  \n",
              "| **AI Engine** | \"What retrofits save the most for *your* home?\"â€”use a simple rule-based model (e.g., \"If building age > 1980, prioritize windows; if < 1960, prioritize insulation\") | TensorFlow.js (no training neededâ€”just logic rules) |  \n",
              "| **Frontend** | A clean, mobile-friendly map where users click their neighborhood â†’ see \"Your Homeâ€™s EcoScore\" + 3 actionable tips | React + Leaflet.js (for maps) |  \n",
              "| **Demo** | Show a real example: \"This house in Bridgeland has an EcoScore of 42%â€”hereâ€™s how to get it to 70% with $2k in upgrades\" | Figma for mockups, then build a live prototype in 6 hours |  \n",
              "\n",
              "### ðŸš€ Why This Wins  \n",
              "- **Itâ€™s not just codeâ€”itâ€™s a story**: Start your pitch with: *\"Imagine a grandmother in a 1950s house in Bowness. Sheâ€™s worried about high bills and climate change, but doesnâ€™t know where to start. EcoPulse gives her a clear pathâ€”no jargon, just savings.\"*  \n",
              "- **Real partnerships**: Mention youâ€™d partner with **Calgary Environmental Network** or **Alberta Energy** for credibility (even if just in the pitch).  \n",
              "- **Scalable vision**: \"This could grow into a city-wide retrofit programâ€”imagine Calgary becoming North Americaâ€™s greenest city by 2030.\"  \n",
              "\n",
              "### ðŸ’¡ Backup Ideas (If You Want Options)  \n",
              "- **\"Wildfire Guardian\"**: A voice-first app for Elders in wildfire-prone areas (e.g., Kananaskis) that alerts them to smoke via phone camera + AI. Uses **Googleâ€™s Speech-to-Text API** + **TensorFlow Lite** for image analysis. *Why it works*: Solves a *critical* Alberta problem with accessibility at its core.  \n",
              "- **\"RezConnect\"**: A voice-based app for Indigenous communities to access healthcare, language learning, or local newsâ€”no typing needed. Integrate **Cree/Siksika language support** via open-source tools. *Why it works*: Deeply respectful, socially impactful, and addresses Calgaryâ€™s Indigenous population (1 in 8 Calgarians are Indigenous).  \n",
              "\n",
              "### ðŸ† Pro Tips to Impress Judges  \n",
              "1. **Start with the problem, not the tech**: \"Calgary has 100,000 aging buildings wasting energy. Hereâ€™s how we fix it.\"  \n",
              "2. **Show, donâ€™t tell**: Have a *live demo* of your MVPâ€”even if itâ€™s just 1-2 features working.  \n",
              "3. **Keep it human**: Show a photo of a real Calgary home, or a quote from a resident.  \n",
              "4. **Mention partnerships**: \"Weâ€™d work with the City of Calgary to integrate this into their Green Home Program.\"  \n",
              "5. **Own the \"why\"**: \"This isnâ€™t just about saving moneyâ€”itâ€™s about making Calgary resilient for future generations.\"  \n",
              "\n",
              "> ðŸ’¬ **Remember**: Judges see 100+ projects. The one that **solves a local problem with heart, simplicity, and real data** will stand out. You donâ€™t need a fully polished appâ€”just a **compelling prototype + a story that makes them feel it matters**.  \n",
              "\n",
              "Youâ€™ve got this! ðŸŒŸ Calgaryâ€™s future is being built right here, right now. Go make something that changes lives. And when youâ€™re coding at 3 AM, remember: **24 hours is enough to change the world.**  \n",
              "\n",
              "*P.S. Need help brainstorming your pitch? Reply with your ideaâ€”Iâ€™ll give you feedback!* ðŸ’¬"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "resp_2 = client.chat(model=selected_model, messages=messages, stream=False)\n",
        "text_2 = resp_2.get(\"message\", {}).get(\"content\", \"\")\n",
        "display(Markdown(text_2))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Try this next\n",
        "- Change the user prompt to your own hackathon theme.\n",
        "- Ask for a 30-second pitch and a simple MVP plan.\n",
        "- Ask for judging criteria and how to optimize for each one.\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "calgaryhacks2026-ibm-workshop",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
